{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_TFL_dist(prev_container, curr_container, focal, pp):\n",
    "    norm_prev_pts, norm_curr_pts, R, foe, tZ = prepare_3D_data(prev_container, curr_container, focal, pp)\n",
    "    if (abs(tZ) < 10e-6):\n",
    "        print('tz = ', tZ)\n",
    "    elif (norm_prev_pts.size == 0):\n",
    "        print('no prev points')\n",
    "    elif (norm_prev_pts.size == 0):\n",
    "        print('no curr points')\n",
    "    else:\n",
    "        curr_container.corresponding_ind, curr_container.traffic_lights_3d_location, curr_container.valid = calc_3D_data(\n",
    "            norm_prev_pts, norm_curr_pts, R, foe, tZ)\n",
    "    return curr_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_3D_data(prev_container, curr_container, focal, pp):\n",
    "    norm_prev_pts = normalize(prev_container.traffic_light, focal, pp)\n",
    "    norm_curr_pts = normalize(curr_container.traffic_light, focal, pp)\n",
    "    R, foe, tZ = decompose(np.array(curr_container.EM))\n",
    "    return norm_prev_pts, norm_curr_pts, R, foe, tZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_3D_data(norm_prev_pts, norm_curr_pts, R, foe, tZ):\n",
    "    norm_rot_pts = rotate(norm_prev_pts, R)\n",
    "    pts_3D = []\n",
    "    corresponding_ind = []\n",
    "    validVec = []\n",
    "    for p_curr in norm_curr_pts:\n",
    "        corresponding_p_ind, corresponding_p_rot = find_corresponding_points(p_curr, norm_rot_pts, foe)\n",
    "        Z = calc_dist(p_curr, corresponding_p_rot, foe, tZ)\n",
    "        valid = (Z > 0)\n",
    "        if not valid:\n",
    "            Z = 0\n",
    "        validVec.append(valid)\n",
    "        P = Z * np.array([p_curr[0], p_curr[1], 1])\n",
    "        pts_3D.append((P[0], P[1], P[2]))\n",
    "        corresponding_ind.append(corresponding_p_ind)\n",
    "    return corresponding_ind, np.array(pts_3D), validVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(pts, focal, pp):\n",
    "    # transform pixels into normalized pixels using the focal length and principle point\n",
    "    result = []\n",
    "    for p in pts:\n",
    "        result.append([(p[0] - pp[0])/focal, (p[1] - pp[1])/focal])\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnormalize(pts, focal, pp):\n",
    "    # transform normalized pixels into pixels using the focal length and principle point\n",
    "    result = []\n",
    "\n",
    "    for p in pts:\n",
    "        result.append([(p[0] * focal + pp[0]), (p[1] * focal + pp[1])])\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose(EM):\n",
    "    # extract R, foe and tZ from the Ego Motion\n",
    "    R = EM[:3, :3]\n",
    "\n",
    "    tx = EM[0, 3]\n",
    "    ty = EM[1, 3]\n",
    "    tz = EM[2, 3]\n",
    "\n",
    "    foe = np.array([tx/tz, ty/tz])\n",
    "    return R, foe, tz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(pts, R):\n",
    "    # rotate the points - pts using R\n",
    "    result = []\n",
    "    for p in pts:\n",
    "        temp = R.dot(np.array([p[0], p[1], 1]))\n",
    "        result.append([temp[0]/temp[2], temp[1]/temp[2]])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the epipolar line between p and foe\n",
    "# run over all norm_pts_rot and find the one closest to the epipolar line\n",
    "# return the closest point and its index\n",
    "def find_corresponding_points(p, norm_pts_rot, foe):\n",
    "    part_one = ( foe[1] - p[1] ) / ( foe[0] - p[0] )\n",
    "    part_two = ( ( p[1] * foe[0] ) - ( foe[1] * p[0] ) ) / ( foe[0] - p[0] )\n",
    "\n",
    "    mechane = math.sqrt(part_one*part_one + 1)\n",
    "    closet_point = -1\n",
    "    index = -1\n",
    "    point = -1\n",
    "    \n",
    "    for i in range(len(norm_pts_rot)):\n",
    "        distance = abs((part_one*norm_pts_rot[i][0] + part_two - norm_pts_rot[i][1]))/mechane\n",
    "        if(closet_point == -1 or distance < closet_point):\n",
    "            closet_point = distance\n",
    "            index = i\n",
    "            point = norm_pts_rot[i]\n",
    "    return index, point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the distance of p_curr using x_curr, x_rot, foe_x and tZ\n",
    "# calculate the distance of p_curr using y_curr, y_rot, foe_y and tZ\n",
    "# combine the two estimations and return estimated Z\n",
    "def calc_dist(p_curr, p_rot, foe, tZ):\n",
    "    zx = (tZ * (foe[0] - p_rot[0]) )/(p_curr[0] - p_rot[0])\n",
    "    zy = (tZ * (foe[1] - p_rot[1])) / (p_curr[1] - p_rot[1])\n",
    "\n",
    "    return (zy+zx)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
